{
  "comments": [
    {
      "key": {
        "uuid": "2b17e08c_c53e5a02",
        "filename": "liblog/logd_write.c",
        "patchSetId": 2
      },
      "lineNbr": 222,
      "author": {
        "id": 1005146
      },
      "writtenOn": "2015-02-16T14:44:06Z",
      "side": 1,
      "message": "Only logging this into the events stream eliminates something we found valuable.  Our perspective is that of somebody analyzing the content of the logs.  If I see log message A in thread X, then later see log message C in thread X, and I expected to see log message B in thread X in between, but didn\u0027t, I want to see the \"Dropped X\" messages for thread X, so that I can distinguish between a log drop and an actual bug.",
      "range": {
        "startLine": 222,
        "startChar": 20,
        "endLine": 222,
        "endChar": 33
      },
      "revId": "2353fa6a306f74f599e162a46616bc3378124278",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "2b17e08c_08c887ac",
        "filename": "liblog/logd_write.c",
        "patchSetId": 2
      },
      "lineNbr": 222,
      "author": {
        "id": 1005146
      },
      "writtenOn": "2015-02-16T14:46:03Z",
      "side": 1,
      "message": "Hmm, I see your comments about using \u0027logcat -d -b main -b events\u0027 to do the interleaving.  The problem for us is that we typically use logs from our persistent reader collected passively by other users, and the streams aren\u0027t interleaved.",
      "parentUuid": "2b17e08c_c53e5a02",
      "range": {
        "startLine": 222,
        "startChar": 20,
        "endLine": 222,
        "endChar": 33
      },
      "revId": "2353fa6a306f74f599e162a46616bc3378124278",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "8885328c_406d8e93",
        "filename": "liblog/logd_write.c",
        "patchSetId": 2
      },
      "lineNbr": 222,
      "author": {
        "id": 1032276
      },
      "writtenOn": "2015-02-23T16:03:51Z",
      "side": 1,
      "message": "Interleaving is somewhat specific to your re-logging infrastructure. I will look into an adjustment to logd/logcat (as hinted above) that will help address your concerns over interleaving.\n\nYour logging infrastructure breaks our security concerns over PII by storing the data in persistent files. What really needs to be done is that the bugreport mechanism needs to be adjusted to address your needs. Please advise on the shortcomings you have with bugreports so we may fix it to work for you.",
      "parentUuid": "2b17e08c_08c887ac",
      "range": {
        "startLine": 222,
        "startChar": 20,
        "endLine": 222,
        "endChar": 33
      },
      "revId": "2353fa6a306f74f599e162a46616bc3378124278",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "a880367a_01654a7f",
        "filename": "liblog/logd_write.c",
        "patchSetId": 2
      },
      "lineNbr": 222,
      "author": {
        "id": 1032276
      },
      "writtenOn": "2015-02-23T16:03:51Z",
      "side": 1,
      "message": "I understand. Please be advised that your reaction is a result of FUD associated with a _bug_ that you had thankfully resolved in logd; hopefully never to bite us again.\n\nI am not comfortable with creating a statistical infrastructure to record TID and LogID for each associated log drop, then play them back. The goal is to re-establish trust, I am sorry I broke that trust. But I still need/want an inexpensive mechanism to report logging failures if they occur in order to take corrective action on the platform. This message is to be considered \u0027fatal\u0027 from the logging perspective and I need to make that more prominent to the observer is my take (I will think about that). My gut tell me that the event needs to be special-cased in logd or logcat ...\n\nAs for being able to continue to triage a problem in the face of data-loss, almost all scenarios one can comes up with will not benefit triage with a more specific loss statistic. The reaction should be to fix the platform problem (hopefully one line in init.rc, and not fix a bug in the logger) and stop limping along.\n\nNB: putting 10000 into /proc/sys/net/unix/dgram_max_qlen and restarting logd can be done without adjusting the platform init.rc file. That should have _bypassed_ the bug in logd that was fixed by your CL.",
      "parentUuid": "2b17e08c_c53e5a02",
      "range": {
        "startLine": 222,
        "startChar": 20,
        "endLine": 222,
        "endChar": 33
      },
      "revId": "2353fa6a306f74f599e162a46616bc3378124278",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "f25ea2fc_98fb95fd",
        "filename": "liblog/logd_write.c",
        "patchSetId": 2
      },
      "lineNbr": 222,
      "author": {
        "id": 1005146
      },
      "writtenOn": "2015-03-04T21:55:47Z",
      "side": 1,
      "message": "Understood and agree about the FUD.\n\nMaking the failure more prominent is exactly what I\u0027d like as well.  Absent some automated monitoring of the event log stream in all test setups (both passive and active), we\u0027re relying on those actually viewing the logs to let us know that it\u0027s broken.  The automated monitoring itself wouldn\u0027t really help in the case of a single user passing some logs along ad-hoc, but as you say maybe that\u0027s just the FUD talking.\n\nI suppose adding a smoke test to our CI that introduces some stress and then looks for the issue in the event stream would be a good thing regardless.\n\nThanks for the effort on this.",
      "parentUuid": "a880367a_01654a7f",
      "range": {
        "startLine": 222,
        "startChar": 20,
        "endLine": 222,
        "endChar": 33
      },
      "revId": "2353fa6a306f74f599e162a46616bc3378124278",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "f25ea2fc_3863698f",
        "filename": "liblog/logd_write.c",
        "patchSetId": 2
      },
      "lineNbr": 222,
      "author": {
        "id": 1005146
      },
      "writtenOn": "2015-03-04T21:55:47Z",
      "side": 1,
      "message": "Bugreports work well for certain situations, but are too large of a hammer for many of the things we do, and too small of one for others.  I don\u0027t know how you could make them work well in all situations.  The RAM-based log buffers don\u0027t have enough depth for solving network-related issues or other things that manifest over time.\n\nAs for PII, we don\u0027t log to persistent files on consumer devices.  We use it for testing.",
      "parentUuid": "8885328c_406d8e93",
      "range": {
        "startLine": 222,
        "startChar": 20,
        "endLine": 222,
        "endChar": 33
      },
      "revId": "2353fa6a306f74f599e162a46616bc3378124278",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "f25ea2fc_1bd3ff55",
        "filename": "liblog/logd_write.c",
        "patchSetId": 2
      },
      "lineNbr": 222,
      "author": {
        "id": 1032276
      },
      "writtenOn": "2015-03-04T22:04:21Z",
      "side": 1,
      "message": "If you dogfood test with ro.logd.size\u003d4M (or for example ro.logd.main.size\u003d4M for _one_ log buffer) set in init.rc for eng or userdebug builds you may have that large, at least one day long, log buffer you are looking for, with regards to tracking network-related issues. 32M on all buffers would give you a week of coverage; but at the cost of OOM killer ...\n\nbugreports would be very unhappy if you did this ;-}",
      "parentUuid": "f25ea2fc_3863698f",
      "range": {
        "startLine": 222,
        "startChar": 20,
        "endLine": 222,
        "endChar": 33
      },
      "revId": "2353fa6a306f74f599e162a46616bc3378124278",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "526daeb2_f3c750dd",
        "filename": "liblog/logd_write.c",
        "patchSetId": 2
      },
      "lineNbr": 222,
      "author": {
        "id": 1005146
      },
      "writtenOn": "2015-03-04T22:13:00Z",
      "side": 1,
      "message": "Yeah, that\u0027s the problem, although I can\u0027t really say what I think on this topic without publicly bashing RIL vendors.  Cranking up the RAM buffer size doesn\u0027t work for Dogfooding, because it invalidates a bunch of others things we\u0027re monitoring.  A true Tragedy of the (Dogfood) Commons... and an inherent flaw in on-target diagnostics.  Oh well.",
      "parentUuid": "f25ea2fc_1bd3ff55",
      "range": {
        "startLine": 222,
        "startChar": 20,
        "endLine": 222,
        "endChar": 33
      },
      "revId": "2353fa6a306f74f599e162a46616bc3378124278",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "f25ea2fc_3ba44384",
        "filename": "liblog/logd_write.c",
        "patchSetId": 2
      },
      "lineNbr": 222,
      "author": {
        "id": 1032276
      },
      "writtenOn": "2015-03-04T22:22:25Z",
      "side": 1,
      "message": "ro.logd.radio.size\u003d64K\n\nBazinga",
      "parentUuid": "526daeb2_f3c750dd",
      "range": {
        "startLine": 222,
        "startChar": 20,
        "endLine": 222,
        "endChar": 33
      },
      "revId": "2353fa6a306f74f599e162a46616bc3378124278",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "6b447857_af749932",
        "filename": "liblog/logd_write.c",
        "patchSetId": 2
      },
      "lineNbr": 240,
      "author": {
        "id": 1032276
      },
      "writtenOn": "2015-02-13T00:39:47Z",
      "side": 1,
      "message": "\u0027dropped\u0027 can get damaged by multiple threads feeding log messages at the same time. We can not afford to use locking as it adds considerable overhead. Explore means to locklessly(sic) improve the reliability of the \u0027dropped\u0027 value.\n\nWhat does not get lost in the shuffle is that this event tells us messages were dropped, regardless if the number is correct or not. This piece of information is more valuable than the quantity.",
      "range": {
        "startLine": 219,
        "startChar": 0,
        "endLine": 240,
        "endChar": 5
      },
      "revId": "2353fa6a306f74f599e162a46616bc3378124278",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "ab3af0c2_d45e5230",
        "filename": "liblog/logd_write.c",
        "patchSetId": 2
      },
      "lineNbr": 240,
      "author": {
        "id": 1001401
      },
      "writtenOn": "2015-02-13T00:57:26Z",
      "side": 1,
      "message": "Can we use an atomic set here and and atomic inc below?",
      "parentUuid": "6b447857_af749932",
      "range": {
        "startLine": 219,
        "startChar": 0,
        "endLine": 240,
        "endChar": 5
      },
      "revId": "2353fa6a306f74f599e162a46616bc3378124278",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "cb5e442b_d0c9b45e",
        "filename": "liblog/logd_write.c",
        "patchSetId": 2
      },
      "lineNbr": 240,
      "author": {
        "id": 1032276
      },
      "writtenOn": "2015-02-13T02:52:56Z",
      "side": 1,
      "message": "I was testing it already ... but decided to use atomic_add and inc",
      "parentUuid": "ab3af0c2_d45e5230",
      "range": {
        "startLine": 219,
        "startChar": 0,
        "endLine": 240,
        "endChar": 5
      },
      "revId": "2353fa6a306f74f599e162a46616bc3378124278",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "6b2558ee_67905236",
        "filename": "liblog/logd_write.c",
        "patchSetId": 2
      },
      "lineNbr": 240,
      "author": {
        "id": 1005146
      },
      "writtenOn": "2015-02-16T14:44:06Z",
      "side": 1,
      "message": "My original proposal used __thread to avoid this, which is a GNU extension.  It looks like C++11 has a standard mechanism (thread_local), but I didn\u0027t try it.  I guess if you\u0027re using atomic on a normal static then you don\u0027t care about thread-specific counts.",
      "parentUuid": "cb5e442b_d0c9b45e",
      "range": {
        "startLine": 219,
        "startChar": 0,
        "endLine": 240,
        "endChar": 5
      },
      "revId": "2353fa6a306f74f599e162a46616bc3378124278",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "6b2558ee_a7a9aa6c",
        "filename": "liblog/logd_write.c",
        "patchSetId": 2
      },
      "lineNbr": 240,
      "author": {
        "id": 1005146
      },
      "writtenOn": "2015-02-16T14:52:38Z",
      "side": 1,
      "message": "This says nothing about performance impacts, though.  If I recall correctly from our rough profiling, we were looking at a penalty of about 80 ns on one of our low-tier devices (Moto E).  At the time, we figured it was worth it for at least our dev builds.",
      "parentUuid": "6b2558ee_67905236",
      "range": {
        "startLine": 219,
        "startChar": 0,
        "endLine": 240,
        "endChar": 5
      },
      "revId": "2353fa6a306f74f599e162a46616bc3378124278",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "2b2600b6_d07782b6",
        "filename": "liblog/logd_write.c",
        "patchSetId": 2
      },
      "lineNbr": 310,
      "author": {
        "id": 1032276
      },
      "writtenOn": "2015-02-13T00:39:47Z",
      "side": 1,
      "message": "We should limit to INT32_MAX/",
      "range": {
        "startLine": 310,
        "startChar": 8,
        "endLine": 310,
        "endChar": 18
      },
      "revId": "2353fa6a306f74f599e162a46616bc3378124278",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "2b17e08c_e541d67c",
        "filename": "liblog/logd_write.c",
        "patchSetId": 2
      },
      "lineNbr": 310,
      "author": {
        "id": 1005146
      },
      "writtenOn": "2015-02-16T14:44:06Z",
      "side": 1,
      "message": "We went with only 8 bits, since we figured past 255 drops the precision just wasn\u0027t interesting anymore.  Our perspective is that of somebody analyzing the log content, though, not profiling the system for logging throughput.",
      "parentUuid": "2b2600b6_d07782b6",
      "range": {
        "startLine": 310,
        "startChar": 8,
        "endLine": 310,
        "endChar": 18
      },
      "revId": "2353fa6a306f74f599e162a46616bc3378124278",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889",
      "unresolved": false
    }
  ]
}