{
  "comments": [
    {
      "key": {
        "uuid": "2d5466e3_53a3b6b0",
        "filename": "init/parser/input_stream.cpp",
        "patchSetId": 1
      },
      "lineNbr": 28,
      "author": {
        "id": 1076138
      },
      "writtenOn": "2015-07-30T17:05:52Z",
      "side": 1,
      "message": "Would it make sense for this to return a smarter struct that would prevent OOB reads?",
      "range": {
        "startLine": 28,
        "startChar": 30,
        "endLine": 28,
        "endChar": 61
      },
      "revId": "f99f8a79635d8f2904edd45a8fd532d2315d76ce",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "8d9472c2_e1bce208",
        "filename": "init/parser/input_stream.cpp",
        "patchSetId": 1
      },
      "lineNbr": 28,
      "author": {
        "id": 1003224
      },
      "writtenOn": "2015-07-30T17:07:27Z",
      "side": 1,
      "message": "(that\u0027s another reason i\u0027d like to move to just reading files in as a std::string.)",
      "parentUuid": "2d5466e3_53a3b6b0",
      "range": {
        "startLine": 28,
        "startChar": 30,
        "endLine": 28,
        "endChar": 61
      },
      "revId": "f99f8a79635d8f2904edd45a8fd532d2315d76ce",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "ed3dee9f_31eb8aec",
        "filename": "init/parser/input_stream.h",
        "patchSetId": 1
      },
      "lineNbr": 30,
      "author": {
        "id": 1076138
      },
      "writtenOn": "2015-07-30T17:05:52Z",
      "side": 1,
      "message": "What are we doing with indentation in the end?",
      "range": {
        "startLine": 30,
        "startChar": 0,
        "endLine": 30,
        "endChar": 2
      },
      "revId": "f99f8a79635d8f2904edd45a8fd532d2315d76ce",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "0d6242c0_fa2645ea",
        "filename": "init/parser/input_stream.h",
        "patchSetId": 1
      },
      "lineNbr": 35,
      "author": {
        "id": 1076138
      },
      "writtenOn": "2015-07-30T17:05:52Z",
      "side": 1,
      "message": "Nit: past?",
      "range": {
        "startLine": 35,
        "startChar": 13,
        "endLine": 35,
        "endChar": 19
      },
      "revId": "f99f8a79635d8f2904edd45a8fd532d2315d76ce",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "4d4d1a59_547562bc",
        "filename": "init/parser/input_stream.h",
        "patchSetId": 1
      },
      "lineNbr": 55,
      "author": {
        "id": 1076138
      },
      "writtenOn": "2015-07-30T17:05:52Z",
      "side": 1,
      "message": "Nit: outlive",
      "range": {
        "startLine": 55,
        "startChar": 38,
        "endLine": 55,
        "endChar": 46
      },
      "revId": "f99f8a79635d8f2904edd45a8fd532d2315d76ce",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "0d57a2ea_d21a422f",
        "filename": "init/parser/scoped_fd.cpp",
        "patchSetId": 1
      },
      "lineNbr": 20,
      "author": {
        "id": 1076138
      },
      "writtenOn": "2015-07-30T17:05:52Z",
      "side": 1,
      "message": "Extra space.",
      "range": {
        "startLine": 20,
        "startChar": 22,
        "endLine": 20,
        "endChar": 26
      },
      "revId": "f99f8a79635d8f2904edd45a8fd532d2315d76ce",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "0d6242c0_7a13158e",
        "filename": "init/parser/scoped_fd.cpp",
        "patchSetId": 1
      },
      "lineNbr": 39,
      "author": {
        "id": 1076138
      },
      "writtenOn": "2015-07-30T17:05:52Z",
      "side": 1,
      "message": "In https://code.google.com/p/chromium/codesearch#chromium/src/base/scoped_generic.h this operation would be called \"Reset\", since it also does Close().",
      "range": {
        "startLine": 39,
        "startChar": 15,
        "endLine": 39,
        "endChar": 19
      },
      "revId": "f99f8a79635d8f2904edd45a8fd532d2315d76ce",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "ed3dee9f_31f2aad8",
        "filename": "init/parser/tokenizer.cpp",
        "patchSetId": 1
      },
      "lineNbr": 64,
      "author": {
        "id": 1076138
      },
      "writtenOn": "2015-07-30T17:05:52Z",
      "side": 1,
      "message": "Nit: backslash",
      "range": {
        "startLine": 64,
        "startChar": 26,
        "endLine": 64,
        "endChar": 35
      },
      "revId": "f99f8a79635d8f2904edd45a8fd532d2315d76ce",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "0d6242c0_da60a102",
        "filename": "init/parser/tokenizer.cpp",
        "patchSetId": 1
      },
      "lineNbr": 67,
      "author": {
        "id": 1076138
      },
      "writtenOn": "2015-07-30T17:05:52Z",
      "side": 1,
      "message": "Doesn\u0027t this mean you should just skip the backslash and continue tokenizing without producing TOK_NEWLINE?",
      "range": {
        "startLine": 63,
        "startChar": 6,
        "endLine": 67,
        "endChar": 28
      },
      "revId": "f99f8a79635d8f2904edd45a8fd532d2315d76ce",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "2a40cc41_36d5a02f",
        "filename": "init/parser/tokenizer.cpp",
        "patchSetId": 1
      },
      "lineNbr": 95,
      "author": {
        "id": 1003224
      },
      "writtenOn": "2015-07-30T17:01:23Z",
      "side": 1,
      "message": "since you\u0027re copying here anyway, wouldn\u0027t it be easier to just read the whole file into a std::string with the existing android::base::ReadFileToString and then have your tokenizer work on a std::string (which is fine for both real life and tests, and lets you remove most of this code)?",
      "revId": "f99f8a79635d8f2904edd45a8fd532d2315d76ce",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "4a3980cf_e55f5eba",
        "filename": "init/parser/tokenizer.cpp",
        "patchSetId": 1
      },
      "lineNbr": 95,
      "author": {
        "id": 1052976
      },
      "writtenOn": "2015-07-30T17:28:21Z",
      "side": 1,
      "message": "I only did it this way to keep the peak memory usage down as you only read a block at a time and only one token is alive at a given point, which should also be small. So unless a token is greater than the blocksize(1024) this code shouldn\u0027t use more than that.\n\nI kinda worry with allocating large buffers that people change default allocators and some are bad at giving back pages to the kernel. \n\ne.g \nbuf \u003d malloc(10MB); free(buf);\nIn some allocators they do not unmap the pages in the free and keep them hot in the heap pool. So the private dirty ram stays at 10MB.\n\nSo I think don\u0027t do arbitrarily big allocations if you don\u0027t have to - maybe I\u0027m stuck in the 90s :)",
      "parentUuid": "2a40cc41_36d5a02f",
      "revId": "f99f8a79635d8f2904edd45a8fd532d2315d76ce",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "0a430851_d297821b",
        "filename": "init/parser/tokenizer.cpp",
        "patchSetId": 1
      },
      "lineNbr": 95,
      "author": {
        "id": 1003224
      },
      "writtenOn": "2015-07-30T17:35:26Z",
      "side": 1,
      "message": "yeah, time to move on. i\u0027m not aware of such problems with either of our allocators, and if there were, we\u0027d want to fix them there.\n\n(also, if you have a 10MiB init.rc, you have other problems :-) )",
      "parentUuid": "4a3980cf_e55f5eba",
      "revId": "f99f8a79635d8f2904edd45a8fd532d2315d76ce",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "2a40cc41_7601e879",
        "filename": "init/parser/tokenizer.cpp",
        "patchSetId": 1
      },
      "lineNbr": 95,
      "author": {
        "id": 1064128
      },
      "writtenOn": "2015-07-30T18:13:52Z",
      "side": 1,
      "message": "+1, I doubt this is a problem.  Init scripts are in the order of a few kbs.  The init scripts in system/core/rootdir is ~25kb, and searching in /device/, I find a strong majority in the \u003c10kb region.  Beyond that, the plan to divide init scripts by services will make them even smaller.  I\u0027d suggest using ReadFileToString directly and not create any new classes beyond this parser.\n\nAs a side note, wouldn\u0027t mmap be better if this were a problem?  It\u0027d let the kernel handle the pages that back the file, while we could copy the tokens out appropriately.",
      "parentUuid": "0a430851_d297821b",
      "revId": "f99f8a79635d8f2904edd45a8fd532d2315d76ce",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889",
      "unresolved": false
    }
  ]
}