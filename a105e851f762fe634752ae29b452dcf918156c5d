{
  "comments": [
    {
      "unresolved": false,
      "key": {
        "uuid": "dd160253_b06b53f8",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 2
      },
      "lineNbr": 0,
      "author": {
        "id": 1290458
      },
      "writtenOn": "2023-04-25T23:28:50Z",
      "side": 1,
      "message": "I\u0027m not a huge fan of this, since these heuristics are always running into corner cases and needing adjustments.\n\nMaybe it\u0027s better to think in terms of the absolute amount of space we want to leave *free* on /data? And then remount can take whatever\u0027s left.",
      "revId": "a105e851f762fe634752ae29b452dcf918156c5d",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "6562d530_e90e41f1",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 2
      },
      "lineNbr": 0,
      "author": {
        "id": 1893074
      },
      "writtenOn": "2023-04-26T06:06:34Z",
      "side": 1,
      "message": "I see what you meant about percentage heuristics and agree with that.\nProviding amount of space we want to leave free actually can solve the problem for us.\n\n**Proposal:** We introduce `fs_mgr.overlayfs.free_data_with_scratch_mb` property alongside with existing `fs_mgr.overlayfs.data_scratch_size_mb` so the logic will be\nfollowing:\n\n1. In case `data_scratch_size_mb` is provided and valid, we use this value to calculate data/scratch size\n2. In case `free_data_with_scratch_mb` is provided and valid we use this one\n3. Otherwise we take 50% of free data storage\n\nBy \"valid\" for `data_scratch_size_mb` and `free_data_with_scratch_mb` I meant we have enough free data space to meet the request (currently we\u0027re not checking data_scratch_size_mb on being valid)\n\nWhat do you think about this approach?",
      "parentUuid": "dd160253_b06b53f8",
      "revId": "a105e851f762fe634752ae29b452dcf918156c5d",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "2fe663ed_b0476473",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 2
      },
      "lineNbr": 0,
      "author": {
        "id": 1337669
      },
      "writtenOn": "2023-04-26T10:22:46Z",
      "side": 1,
      "message": "If the problem is just that _free space in userdata is under utilized_\nhow about we just do:\n\n1. If `data_scratch_size_mb` is provided, use it to calculate. Otherwise use the size of `super`.\n2. Clamp size by ensuring userdata is at least say 85% or 90% free after allocating scratch.\n3. Last verify that the size is at least say 256MiB. So we ensure the allocated scratch is not too tiny to be useful.\n\nMy main motivation is to keep the implementation simple, and not introduce more heuristics that only solve some very specific situations (like what `data_scratch_size_mb` is).",
      "parentUuid": "6562d530_e90e41f1",
      "revId": "a105e851f762fe634752ae29b452dcf918156c5d",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "7d9660bf_50dfe0cd",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 2
      },
      "lineNbr": 0,
      "author": {
        "id": 1893074
      },
      "writtenOn": "2023-04-26T12:00:28Z",
      "side": 1,
      "message": "Let me provide an example to make sure we\u0027re on the same page. The original problem is not enough scratch space allocated for local development cases. Currently, the default flow is used where we allocate 50% of free data for scratch (about 2.7g per CVD by default).\n\nFollowing the logic you proposed (make sure 85-90% of data is available after scratch allocation) we will allocate even less, so probably we need to use a different number (probably 60-40% of available `data` after scratch cut).\n\nAlso, I cannot see the benefits of using `% of available data after scratch cut` (proposed) versus `% of available data` (existing) approach.",
      "parentUuid": "2fe663ed_b0476473",
      "revId": "a105e851f762fe634752ae29b452dcf918156c5d",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "cc682085_cc3f3009",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 2
      },
      "lineNbr": 0,
      "author": {
        "id": 1337669
      },
      "writtenOn": "2023-04-26T12:04:16Z",
      "side": 1,
      "message": "oh sorry, I meant the opposite. \"ensure 10 or 15% of free space\" (now we retain 50%)",
      "parentUuid": "7d9660bf_50dfe0cd",
      "revId": "a105e851f762fe634752ae29b452dcf918156c5d",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "d1eb84a7_2ac67b93",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 2
      },
      "lineNbr": 0,
      "author": {
        "id": 1893074
      },
      "writtenOn": "2023-04-26T12:09:11Z",
      "side": 1,
      "message": "What do you think about taking 75% of available `data` instead of 50% by default then? I assume that users would like to have more overlay rather then `data` when partitions are remounted. So we can keep the logic simple and just modify the param.",
      "parentUuid": "cc682085_cc3f3009",
      "revId": "a105e851f762fe634752ae29b452dcf918156c5d",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "93944989_082cc535",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 2
      },
      "lineNbr": 0,
      "author": {
        "id": 1337669
      },
      "writtenOn": "2023-04-26T12:22:39Z",
      "side": 1,
      "message": "\u003e 75%\n\nIf that works for you then sure? but I\u0027d recommend to go even further and try to snatch something like 90%, so you get as large scratch size as possible. Do keep in mind that we won\u0027t take more than the size of super, so \"over allocating\" scratch is less of a concern, IMO.\n\n---\nregarding \"% of available free space left\" vs \"% of available free space\"\n\nI just think the former would be more deterministic in terms of the space we take?\n\nThe former we ensure the entire /data is at least 25% free,\n\nThe latter we ensure the entire /data is at least \"free size at the time of calculation\" * 25% free, which can be anywhere from 0~25% free?",
      "parentUuid": "cc682085_cc3f3009",
      "revId": "a105e851f762fe634752ae29b452dcf918156c5d",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "6f7ee1b9_d0784725",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 2
      },
      "lineNbr": 0,
      "author": {
        "id": 1893074
      },
      "writtenOn": "2023-04-27T10:23:25Z",
      "side": 1,
      "message": "\u003e regarding \"% of available free space left\" vs \"% of available free space\"\n\nI\u0027m agree that `% of available free space left` is more deterministic, but it can be tricky on the edges, so imagine we have a fresh device (pretty common situation for remount case), so only about 300mb `data` is used. In this case we will leave only 75mb of storage for `data` which is definitely too aggressive. From the other side, 20% may be too much of storage when 70% of `data` is used.\n\nWhat do you think about using linear scale between 20% and 90% so we will take about 20-25% of available storage when device is almost full and about 85-90% when device is fresh and doesn\u0027t have much data.\n\nI think this should be an improvement over existing (always take 50%) approach.\n\nCheck the green columns where I shared the numbers for 8gb device and 20-90% scale depending on current userdata usage (https://docs.google.com/spreadsheets/d/1FQYkPc93BRrXOlps95c1IeOOahhfWW5Z8e6XFrf3sRs/edit#gid\u003d0)",
      "parentUuid": "93944989_082cc535",
      "revId": "a105e851f762fe634752ae29b452dcf918156c5d",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "900048e9_c0c376fb",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 2
      },
      "lineNbr": 0,
      "author": {
        "id": 1893074
      },
      "writtenOn": "2023-04-27T10:23:25Z",
      "side": 1,
      "message": "regarding \"% of available free space left\" vs \"% of available free space\"\n\nI think it doesn\u0027t really matter what we choose here since they behave similarly, but",
      "parentUuid": "93944989_082cc535",
      "revId": "a105e851f762fe634752ae29b452dcf918156c5d",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "1accbe2e_eef5ee26",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 2
      },
      "lineNbr": 0,
      "author": {
        "id": 1337669
      },
      "writtenOn": "2023-04-27T10:49:46Z",
      "side": 1,
      "message": "\u003e  here since they behave similarly,\n\nyeah agree, let\u0027s not focus on this as it\u0027s not the point here\n\n\u003e What do you think about using linear scale between 20% and 90% so we will take about 20-25% of available storage when device is almost full and about 85-90% when device is fresh and doesn\u0027t have much data.\n\nyeah but what I\u0027m suggesting is to use 85-90% (6g *0.9 \u003d 5.4g) when device is fresh and not full.\nIf device is full (say 70% full, so 6*0.3\u003d1.8g of free disk space), then instead of tweaking the percentage (50% of 1.8g is 0.9g; 80% of 1.8g is 1.44g; an increase of 0.9 -\u003e 1.44 barely helps?), just error out and ask user to free up their userdata?",
      "parentUuid": "900048e9_c0c376fb",
      "revId": "a105e851f762fe634752ae29b452dcf918156c5d",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889"
    }
  ]
}